\section{Trigger and event processing}
\section{Object reconstruction}
The physics objects relevant to this analysis are electrons, muons, jets and the missing transverse energy \MET. Here the reconstruction of these objects from the information provided by the CMS detector is described. While the electron and muon candidates used here are reconstructed independent of each other with dedicated algorithms, jets and \MET are provided by the particle flow (PF) algorithm. It combines information from all subdetectors to achieve a consistent description of the full event. 
\subsection{Muon reconstruction and selection}
The track of a muon is reconstructed separately in the inner tracker and the muon system, resulting in a $\textit{tracker track}$ and a $\textit{standalone muon}$. 

Tracks in the inner tracker are reconstructed using a method called Combinatorial Track Finder (CTF)~\cite{Chatrchyan:2014fea}, which performs pattern recognition and track fitting employing a Kalman filter technique~\cite{Fruhwirth1987444}. The track is described by a five-dimensional state vector, whose initial parameters are taken from track seeds, determined from three hits or two hits and a vertex constraint in the pixel detector or the innermost layers of the strip detector. The state vector is extrapolated to the next tracker layer taking into account uncertainties and energy losses due to interactions with the tracker. If tracker hits are found in the modules where they are expected from the extrapolation, they are added to the track candidate. If no hits are found, a ghost hit is added to the track to account for inefficiencies in the hit reconstruction. A track fit is then performed to all hits associated with the track candidate, using again Kalman filtering and smoothing. This procedure is performed iteratively, each time removing the hits already associated to a track candidate and relaxing the requirements on the track seeds to allow for reconstruction of track with low \pt or not originating from the primary interaction. In the reconstruction of the data taken in 2012, seven iterations were performed~\cite{SWGuideIterativeTracking}. 

For the reconstruction of $\textit{standalone muons}$ in the muon system, the hits inside the individual muon chambers are fitted to generate track segments, providing first estimates of the track parameters under the hypothesis that the muon was created in the interaction region and was travelling through the muon system from the inside out. These segments are used as starting points for a track reconstruction using all hits from the DTs, CSCs and RPCs, again using the Kalman filtering technique~\cite{1748-0221-5-03-T03022}.

Tracker tracks are promoted to $\textit{tracker muons}$ when they can be matched to a track segment in the muon detector. $\textit{Standalone muons}$ are matched to tracks from the inner tracker. If a compatible track is found a combined fit to all hits of the track and the $\textit{standalone muon}$ is performed, resulting in a $\textit{global muon}$. The PF algorithm applies further selection requirements to the reconstructed $\textit{global}$ and $\textit{track muons}$, introducing a fourth category, the $\textit{particle flow muon}$~\cite{CMS-PAS-PFT-10-003}. 

Muons selected in this analysis are required to be reconstructed as $\textit{tracker}$, $\textit{global}$ and $\textit{particle flow}$ muons. The $\chi^2$ per degrees of freedom of the track fit must not exceed 10. Several requirements on the information available for the different track fits are made: At least one muon chamber hit must be included in the track fit of the $\textit{global muon}$. For the fit of the $\textit{tracker muon}$ at least one hit in the pixel detector and six layers with hits in the strip detector have to be available. Also the track from the inner tracker has to be matched to at least two track segments in the muon chambers. To ensure that the muon originates from the primary interaction and to suppress backgrounds from cosmic muons the impact parameter of the track with respect to the primary vertex must not exceed $\unit{0.02}{\centi\meter}$ in the $x$-$y$ plane and $\unit{0.1}{\centi\meter}$ in $z$ direction. Selected are muons with a \pt larger than $\unit{10}{\giga\electronvolt}$ and $|\eta|$ less than 2.4. The muon selection is summarized in Table~\ref{tab:muonID}.
\begin{table}
\begin{center}
\begin{tabular}{c|c}
Criterion & Selection \\
\hline \hline 
\multicolumn{2}{c}{Acceptance} \\
\hline
\pt & $> \unit{10}{\giga\electronvolt}$ \\
$|\eta|$ & $< 2.4$ \\
\hline
\multicolumn{2}{c}{Muon ID} \\
\hline
Required to be a & $\textit{tracker muon}$ \\
 & $\textit{global muon}$ \\
 & $\textit{particle flow muon}$ \\
 \hline
 \multicolumn{2}{c}{Track quality} \\
 \hline
  $\chi^2/N_{dof}$ & $< 10 $ \\
  valid muon hits & $> 0 $ \\
  matched stations & $> 1 $ \\
  valid pixel hits & $ > 0 $ \\
  tracker layers with hits & $ > 6 $ \\
\hline
  \multicolumn{2}{c}{Impact parameter} \\
\hline
	$d0 = \sqrt{dx^2 + dy^2}$ & $< \unit{0.02}{\centi\meter}$ \\
	dz & $ < \unit{0.1}{\centi\meter}$ \\  
\end{tabular}
\caption{Summary of requirements of the muon selection.}
\label{tab:muonID}
\end{center}

\end{table}
\subsection{Electron reconstruction and selection}
The signature of an electron in the CMS detector is a track reconstructed by the tracking detectors that leads to a matching cluster of energy reconstructed in the ECAL. In practice this is complicated by the large material budget of the tracking detectors, resulting in a high probability of an electron to loose energy in form of bremsstrahlung. About 35\% of all electrons loose more than 70\% of their energy and for 10\% the energy loss exceeds 95\%~\cite{Baffioni:2006cd}. The reconstruction is further complicated by the large solenoidal magnetic field, which bends the electron's trajectory away from the radiated photons, leading to a spread of the energy in $\phi$ direction. This has to be taken into account both in the tracking algorithms and the clustering of the energy deposits in the ECAL. 

In the ECAL two different algorithms are used to group the energy deposits into clusters and clusters of clusters, called super clusters (SCs), in the barrel and endcap regions of the detector. Both are designed to group together the energy deposits of the electron itself and those of the bremsstrahlung photons. In the of $1.6 < |\eta| < 2.6$ the preshower is located in front of the ECAL and electrons will deposit a fraction of their energy there. The energy deposited in the strips of the preshower between an SC in the ECAL and the primary vertex is summed and added to the energy of this SC~\cite{Anderson:1365024}. ADD SC position calculation and electron charge! CHANGE ALL REFS TO EGM-13-001 once submitted to journal!

In the track reconstruction with Kalman filters as discussed above energy losses due to interactions of the particles with the tracker material are considered to be Gaussian. For electrons, however, this is not sufficient because the dominant energy loss due to bremsstrahlung is a non-gaussian contribution. Electron candidate tracks are therefore fitted with a Gaussian Sum Filtern (GSF) algorithm~\cite{FruhwirtGSFCMS}, which models the non-Gaussian components as a sum of Gaussian distributions. GSF tracking is initiated in two ways. $\textit{ECAL driven seeding}$ requires the presence of a track seed that matches the position of an SC when extrapolating backwards from the ECAL to track~\cite{Baffioni:2006cd}. Alternatively, $\textit{tracker driven seeding}$ is started by tracks that either match the position of ECAL clusters when extrapolated to the ECAL surface, covering the case of no bremsstrahlung, or are of poor quality with only few associated hits~\cite{Chatrchyan:2014fea}. The GSF track and the energy measurement in the ECAL are combined into the final electron candidate. 

Electrons are selected requiring \pt larger than $\unit{10}{\giga\electronvolt}$ and $|\eta| < 2.5$. The gap region between ECAL barrel and endcaps of $1.442 < |\eta| < 1.566$ is exluded. To suppress background from muons that radiate photons electrons with a distance of $\Delta R = \sqrt{\Delta\phi^2 + \Delta \eta^2}$ to the nearest $\textit{global}$ or $\textit{tracker muon}$ less than 0.1 are rejected. Backgrounds from photon conversion, decays of heavy flavour quarks  or charged hadrons are suppressed by a set of selection criteria. The matching of track and supercluster is quantified by the differences between the supercluster position and the parameters of the track extraploated from the vertex to the ECAL surface in $\Delta\phi$ and $\Delta\eta$. As the energy of the electron is contained in the ECAL, the ratio of hadronic energy deposited in the HCAL behind the electron candidate must be small. The energy spread in the ECAL due to bremsstrahlung occurs in $\phi$ direction. Therefore no significant spread of the energy in $\eta$, parametrized as
\begin{equation}
\sigma_{i\eta i\eta} = \frac{\sum\limits_i^{5\times 5} w_i\cdot (\eta_i - \bar{\eta}_{5\times 5})^2}{\sum\limits_{i}^{5\times 5} w_i},
\end{equation}
\begin{equation}
w_i = max(0,4.7 + ln(\frac{E_i}{E_{5 \times 5}})),
\end{equation}
is expected, where for $5\times 5$ crystals around the seed crystal the distance in $\eta$ from the mean $\eta$ of the cluster is summed, weighted by the energy deposit in each crystal. For a well measured electron there is good agreement between the energy deposited in the ECAL and the track momentum measured at the vertex. Therefore the value of $| \frac{1}{E} - \frac{1}{p}|$ must be small. Requirements on the impact parameter of the track with the respect to the vertex are made. Two requirements are applied to reject electrons from converted photons. Only one pixel layer with missing hit is allowed, rejecting most conversions occurring after the first layer of the pixel detectors. To reject also conversion in this first layer and in the beam pipe, vertex fits for the electron track with neighbouring tracks are performed in order to reconstruct the point of conversion. For a prompt electron, the probability of these fits is low. Some of these requirements are already applied on HLT level. In order to select electrons for which the trigger is fully efficient, selections at least as strict are applied at analysis level. The specific requirements are listed in Table~\ref{tab:eleID}, separately for barrel and endcap when appropriate. 
\begin{table}
\begin{center}
\begin{tabular}{c|c|c|c|c}
Criterion & \multicolumn{2}{c|}{Selection at HLT}  & \multicolumn{2}{c}{Selection at Analysis Level}  \\
 & EB & EE & EB & EE \\
\hline \hline 
\multicolumn{5}{c}{Acceptance} \\
\hline
\pt & \multicolumn{2}{c|}{trigger dependent} &  \multicolumn{2}{c}{$> \unit{10}{\giga\electronvolt}$} \\
$|\eta|$ & \multicolumn{2}{c|}{$< 2.5 $} & \multicolumn{2}{c}{$< 2.5 $, excluding $1.442 < |\eta| < 1.566$}  \\

\hline
\multicolumn{5}{c}{ID variables} \\
\hline
$|\Delta \eta |$ & 0.01 & 0.01 & 0.007 & 0.009  \\
$|\Delta \phi |$ & 0.15 & 0.10 & 0.15 & 0.10  \\
$\sigma_{i\eta i\eta}$ & 0.011 & 0.031 & 0.01 & 0.03  \\
$H/E$ & 0.10 & 0.075 & 0.12 & 0.10 \\ 
$|\frac{1}{E} - \frac{1}{p}|$ & \multicolumn{2}{c|}{-} & 0.05 & 0.05 \\
\hline
\multicolumn{5}{c}{Conversion rejection} \\
\hline
 missing pixel hits & \multicolumn{2}{c|}{-} & $\leq1$  & $\leq1$ \\
 vertex fit probability & \multicolumn{2}{c|}{-} & $< 10^{-6}$ & $< 10^{-6}$ \\ 
 \hline
  \multicolumn{5}{c}{Impact parameter} \\
\hline
	$d0 = \sqrt{dx^2 + dy^2}$ & \multicolumn{2}{c|}{-} & $< \unit{0.02}{\centi\meter}$ & $< \unit{0.02}{\centi\meter}$\\
	dz & \multicolumn{2}{c|}{-} & $ < \unit{0.1}{\centi\meter}$ & $ < \unit{0.1}{\centi\meter}$\\  
\end{tabular}
\caption{Summary of requirements of the electron selection.}
\label{tab:eleID}
\end{center}
	
\end{table}
\subsection{Observables reconstructed with Particle Flow}
\subsubsection{The algorithm}
The particle flow (PF) algorithm is designed to combine information from all subdetectors to reconstruct a consistent description of the event, resulting in a list of reconstructed particles. The basic building blocks are PF elements, which are reconstructed in each subdetector separately: Tracks of charged particles in the tracker, energy clusters in the calorimeters and muon tracks in the muon system. A linking algorithm then combines elements into blocks based on their geometrical distance, for example by extrapolating a track into the ECAL and HCAL and searching for compatible clusters. Similarly, calorimeter clusters are linked between the preshower, ECAL, and HCAL and tracks from the tracker are associated with those from the muon system. The reconstruction of $\textit{particle candidates}$ is performed on the elements inside a block. Muons are reconstructed first, followed by electrons, for which, similar to the standard algorithm described above, a refit of the track with the GSF algorithm is performed and bremsstrahlung photons are collected in the ECAL. Lastly, calorimeter clusters compatible with a track are identified as charged hadron, while clusters without a matching track are either categorized as neutral hadrons, or, if no or only small energy deposits in the HCAL exist, as photons~\cite{CMS-PAS-PFT-09-001}. 
\subsubsection{Jets}
The jets of particles produced in the hadronization of quarks and gluons are grouped together by clustering algorithms. An anti-$k_T$ algorithm~\cite{Cacciari:2008gp}, performed using a fast implementation~\cite{Cacciari:2011ma,Cacciari:2005hq}, is used in this analysis.  Input to the clustering are the $\textit{particle candidates}$ reconstructed by the particle flow algorithm.

The anti-$k_T$ algorithm is a sequential clustering algorithm. Two distance measures are introduced, the first between two particles or pseudo-jets $i$ and $j$ and the second between particle or pseudo-jet $i$ and the beam axis: 
\begin{equation}
d_{ij} = min(k_{Ti}^{-2},k_{Tj}^{-2})\frac{\Delta^2_{ij}}{R^2},
\end{equation}
\begin{equation}
d_{iB} = k_{ti}^{-2},
\end{equation}
with $\Delta_{ij}^2 = (y_i-y_j)^2 + (\phi_i - \phi_j)^2$ and $k_{Ti}$, $y_i$, and $\phi_i$ being the transverse momentum, rapidity and azimuth of a particle. For an entity (particle, pseudo-jet) $i$ all distances are calculated. If the smallest is a $d_{ij}$, $i$ and $j$ are combined in a new pseudo-jet. If the smallest distance if the distance to the beam $d_{iB}$, the pseudo-jet is considered a final jet and removed from the list of particles available for clustering. The parameter $R$ governs the size of the resulting jet and is set to 0.5 in this analysis. 

The measured jet energy has to be corrected for energy offsets and the non-uniform and non-linear response of the detector. Each component of the jet's four-momentum vector is corrected by a multiplicative factor~\cite{1748-0221-6-11-P11002}
\begin{equation}
p_{\mu}^{cor} = C \cdot p_{\mu}^{raw}.
\end{equation} 
The correction is applied as a sequence of different factors: 
\begin{equation}
C = C^{L1}_{\text{offset}}(p_T^{raw})\cdot C^{L2L3}_{MC}(p_T^{\prime},\eta)\cdot C^{L2Residual}_{rel}(\eta) \cdot C^{L3Residual}_{abs}(p_T^{\prime\prime}).
\end{equation}
The L1 correction, applied to the raw jet, corrects for offsets due to the underlying event and pileup using a jet area approach. The jet area $A_j$ is determined for each jet and the particles in the event are clustered with a $k_T$ jet clustering algorithm with a distance parameter $R=0.6$, which clusters a large number of soft jets in each event. The median $p_T$ density $\rho$ is then defined as the median of the distribution of $p_{T_j}/A_j$ for all of these jets. Therfore $\rho$ is not influenced by the presence of hard jets from the primary interaction in the event and is a measure for the pileup activity, the underlying event and electronic noise. Jets are then corrected by the factor $C^{L1}_{\text{offset}}(p_T^{raw}) = 1-\frac{(\rho-<\rho_{UE}>)\cdot A_j)}{p_T^{raw}}$, where $<\rho_{UE}>$ is the mean \pt density due to the underlying event, measured in events with no pileup interactions. The L2L3 corrections, derived from Simulation, corrects for the non-linearities and non-uniformities of the detector response to jets of different $\pt$ and $\eta$ and is applied to the offset-corrected jet. To correct for the differences between Simulation and real data, jets in data events are further corrected for the residual differences between the two.  

In this analysis, the \pt of a jet is required to exceed $\unit{40}{\giga\electronvolt}$ and jets are required to lie inside the fiducial volume of the ECAL of $|\eta| < 3.0$. A set of loose quality selections is applied to suppress jets reconstructed because of detector noise, ensuring that the jet is reconstructed in more than one subdetector and has more than one constituent. As the jet clustering is performed using all reconstructed $\textit{particle candidates}$, jets within $\Delta R = 0.4$ to leptons identified with the criteria described above are rejected. 

Because of their long lifetime, b-jets decay at a measurable distance from their production vertex, allowing for the reconstruction of a secondary vertex. In this analysis the $\textit{combined}$ $\textit{secondary}$ $\textit{vertex}$ (CSV) algorithm is used. Likelihood ratios based on a variety of variables characterizing the secondary vertices and the tracks inside the jet are used to construct a single discriminator. If it's value exceeds a given threshold, the jet is tagged as originating from a b-quark~\cite{Chatrchyan:2012jua}. The performance of the b-tagging algorithms have been measured on the $\sqrt{s} = \unit{8}{\tera\electronvolt}$ dataset~\cite{CMS-DP-2013-005}. The average identification efficiency as a function of the discriminator value is shown on the left side of Figure~\ref{fig:bTagging}. For the medium working point of 0.679, chosen in this analysis, the efficiency is about 70\% while the probability to misidentify a jet originating from a light quark as a b-jet is between 1\% and 3\%, depending on the \pt of the jet, as shown on the right side of Figure~\ref{fig:bTagging}. In this analysis b-jets are considered with a \pt larger than $\unit{30}{\giga\electronvolt}$ and $|\eta| < 2.4$. 
\begin{figure}[htbp]
\centering
\begin{minipage}[t]{0.49\textwidth}
  \includegraphics[width=\textwidth]{plots/RECO/bTagEfficiency.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
\includegraphics[width=\textwidth]{plots/RECO/bTagMisID.png}
\end{minipage}
\caption{Performance of the CSV b-tagging algorithm. Shown is the identification efficiency as a function of the discriminator value (left) and the probability of misidentifying a jet originating from a light quark as a b-jet (right)~\cite{CMS-DP-2013-005}.}
\label{fig:bTagging}
\end{figure} 

\subsubsection{Missing transverse energy}
As the transverse momenta of the initial partons are negligible compared to their large momenta in beam direction, the sum of the transverse momenta of all particles produced in the interaction is essentially zero because of conservation of momentum. For the reconstructed event this is not necessarily the case, leading to a missing transverse energy (\MET) different from zero. The measurements in the detector have a finite resolution and are subject to detector noise and are subject to gaps in the detector acceptance. Also, particles that are only weakly interacting, such as neutrinos, are not detected by CMS and cause an imbalance of the transverse momentum sum. As this imbalance is the only experimental signature of this class of particles, a good \MET resolution is a key factor for the discovery of processes that include the production of new weakly interaction particles. 

Several algorithms have been developed in CMS to reconstruct \MET~\cite{7TeVMETPaper}. Calorimetric (Calo) \METVec is calculated as the negative vector sum of the energy deposits in each calorimeter tower. The small energy deposits from muons are replaced by the \pt measurements of muons. A further correction is introduced in the track-corrected (TC) \METVec. For well reconstructed tracks, the track measurement is more precise than the measurement of a hadron's energy in the HCAL. Therefore, for tracks not associated with an electron or  muon, the track measurement is used in the calculation of \METVec. The energy deposit in the calorimeter is excluded, based on a model of the calorimeter response, treating all hadrons as pions. In contrast to these subdetector-based approaches, the event description of the particle flow algorithm can be used to calculate \METVec. It is defined as the negative vector sum over the \pt vectors of all particle flow candidates:
\begin{equation}
 \METVec = - \sum\limits_{\text{PF candidates}} \vec{p}_T^i.
\end{equation}
Comparing the resolution for the \MET components in $x$ and $y$ direction, as shown in Figure~\ref{fig:METReso} for the data collected in 2011, PF \MET performs best of the three algorithms and is therefore used in this analysis.
\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{plots/RECO/METResolution.png}
\caption{Calibrated \MET resolution as a function of the sum of the \Et of all particle flow candidates in an event. Shown are Calo \MET in black, TC \MET in red and PF \MET in blue~\cite{7TeVMETPaper}.}
\label{fig:METReso}
\end{center}
\end{figure}

Several corrections can be applied to the calculation of \MET. The $\textit{type-I}$ corrections propagate the corrections to the jet energy to the \MET calculation for all jets with \pt larger than $\unit{10}{\giga\electronvolt}$ and with less than 90\% of their energy deposited in the ECAL. The effects of pileup on the \MET reconstruction can be mitigated by applying $\textit{type-0}$ corrections, which are calculated on minimum bias events to parametrize the effects of such interactions on \MET. Further corrections can be applied to correct for modulations of the \MET in $\phi$~\cite{CMS-PAS-JME-12-002}. As this analysis searches for events with a large genuine \MET and is therefore not very sensitive to \MET introduced by resolution effect, none of these corrections are applied. However, $\textit{type-I}$ corrected PF \MET is considered as a cross check. 
\subsubsection{Lepton isolation}
While the lepton selection criteria described above are sufficient to reject backgrounds from particles misidentified as leptons, the do not suppress real leptons not originating from the primary interaction. As these are often produced in decay of heavy flavour quarks inside a jet, are more suitable criterion is to consider the amount of activity in the detector close to the lepton candidate, called lepton isolation. In this analysis, particle based isolation is used. For this the energy deposited by charged hadron, neutral hadron, and photon particle flow candidates in a cone of $\Delta R = 0.3$ around the lepton is summed:
\begin{equation}
\text{Iso} = \sum\limits_{\text{charged hadrons}} E_T + \sum\limits_{\text{neutral hadrons}} E_T + \sum\limits_{\text{photons}} E_T.
\end{equation}
The calculation of the isolation is distorted by pileup if PF candidates originating from pileup interactions lie within the cone and are counted in the isolation sum. This is easily remedied for charged hadrons, as those originating from a pileup vertex can be excluded from the calculation. For neutral hadrons and photons there is no track that can be associated to a vertex and a direct identification as pileup particles is not possible. Different approaches are pursued to correct for this contribution for electrons and muons. In both cases an estimate for the contribution of neutral pileup is subtracted from the isolation sum, which changes to:
\begin{equation}
\text{Iso} = \sum\limits_{\text{charged hadrons}} E_T + max(0, \sum\limits_{\text{neutral hadrons}} E_T + \sum\limits_{\text{photons}} E_T - \sum\limits_{\text{neutral PU}} E_T). 
\label{eq:iso}
\end{equation}
For electrons the correction is similar to the L1 offset correction for jets described above. As a measure for the pileup contribution in the isolation cone the median \pt density in the event $\rho$ is multiplied by the effective area of the electron in the detector, which is calculated in bins of $\eta$. The pileup correction is therefore defined as $\sum\limits_{\text{neutral PU}} E_T = \rho\cdot A^{eff}_{\text{electron}}$. For muons $\Delta \beta$ corrections are applied. Here it is utilized that on average the contribution of neutral particles from pileup is half that of charged particles, leading to a correction defined as $\sum\limits_{\text{neutral PU}} E_T = 0.5\cdot \sum\limits_{\text{charged PU}} E_T$. Because of the stochastic nature of these approaches, overcorrection is possible. Therefore, no negative contribution from neutral particles is allowed in equation~\ref{eq:iso}. ADD PLOTS SHOWING ISO VS NVTX

For both electrons and muons the isolation sum must not exceed $0.15\cdot \pt$ of the lepton candidate. \TODO{make plots illustrating the choise}
\section{Datasets}
\section{Event selection}
A series of selection criteria are applied to the events to select signal-like topologies and reduce the contributions from Standard Model backgrounds to the final sample. Also requirements are defined to select control regions enriched in certain SM processes for the purpose of background prediction and the validation of methods. Additionally, events are reject that exhibit signs of detector noise or are otherwise not suited for analysis. 
\subsection{Event cleaning}
As a first step in the selection of reconstructed events, a series of quality requirements is applied. 
The quality of the data recorded by the CMS detector is assessed in several automated or manual steps, summarised as $\textit{Data quality monitoring (DQM)}$~\cite{DQM}. For each lumi section this results in a binary decision, flagging it as either $\textit{good}$ or $\textit{bad}$, accepting only those lumi sections for which all subdetectors were fully operational during data taking and no known problems occurred in the reconstruction of the events.

To reject non-collision events, vertex information is used. To reconstruct vertices, tracks fulfilling certain quality requirements are clustered into vertices with a deterministic annealing algorithm~\cite{DertermisiticAnnealing,Chatrchyan:2014fea}. The vertex position is fitted using an adaptive vertex fitter~\cite{Fruehwirth:1027031}, where a weight $w_i$ between 0 and 1 is assigned to every track, based on the likelihood of that track being correctly associated with the vertex. The presence of at least one primary vertex is required whose distance to the interaction point is less than $\unit{24}{\centi\meter}$ in $z$ direction and $\unit{2}{\centi\meter}$ in the $x$-$y$ plane. Also the number of degrees of freedom, defined as~\cite{Chatrchyan:2014fea}:
\begin{equation}
n_{dof} = -3 + 2 \sum\limits_{i=1}^{N_{tracks}} w_i,
\end{equation}
is required to be greater than four.  

As it relies on the balance of all reconstructed objects, \MET is especially sensitive to distortions of the event reconstruction by noise or particles not originating from the proton proton collisions. Several sources of these distortions have been identified during the data taking and filters have been developed in CMS to reject events matching their signatures~\cite{CMS-PAS-JME-12-002}. This includes filters for signal produced by interactions of the beam with gas molecules in the beam pipe or of protons in the beam halo with the LHC infrastructure, anomalous noise in the HCAL or ECAL, dead ECAL cells, calibration lasers mistakenly firing during collision events, or failures of the tracking algorithms. The effect of these filters on the tails of the \MET distribution in dijet events is shown in Figure~\ref{fig:METFilters}, where it can be seen that it is dominated by events that are rejected by the filters for \MET larger than $\unit{300}{\giga\electronvolt}$.
\begin{figure}
\begin{center}
\includegraphics[scale=0.4]{plots/SELECTION/metFilter.pdf}
\caption{Distribution of \MET in dijet events in 2012 data. The open data points show all events, while the black points show the data after application of \MET filters. Simulated Standard Model processes are shown as filled histograms.~\cite{CMS-PAS-JME-12-002}.}
\label{fig:METFilters}
\end{center}
\end{figure}


\subsection{Inclusive dilepton selection}
Events are selected containing two leptons with opposite electric charge, \pt larger than $\unit{20}{\giga\electronvolt}$, and $|\eta|$ smaller than 2.4. The \pt requirement is driven by the thresholds of the dilepton triggers, as discussed in Section~\ref{sec:trigEffs}, while the $|\eta|$ restriction is imposed  by the coverage of the muon system. The acceptance for electrons could in principle be extended to $|\eta| =$ 2.5, but is chosen to be the same for both lepton flavours. Lepton pairs are required to be selected by the corresponding trigger, e.g. a pair of electrons has to have fired the dielectron trigger. If there is more than one pair of leptons fulfilling this basic requirements in one event, the pair with the largest sum of lepton \pt is chosen. 

As the symmetry between lepton flavours is a key ingredient of the methods to estimate the backgrounds from Standard Model processes, events for which these symmetries are potentially violated are rejected.

As the efficiency to reconstruct electrons is reduced in the overlap region between the barrel and endcap detectors of the ECAL, the relative event yield for events with electrons with $|\eta|$ between 1.4 and 1.6 is reduced compared to those with muons in this range. This distribution of the $|\eta|$ of the leading lepton in \EE and  \MM events is shown in Figure~\ref{fig:cutJustification} (left), illustrating the greatly increased difference between the event yields for electrons and muons in the overlap region. Events containing a lepton with a pseudorapidity of $1.4<|\eta|<1.6$ are therefore rejected. Also an increasing difference between electrons and muons can be seen for events were the leading leptons is in the endcap region of the detector. This is one of the reasons for splitting the event sample in two categories: $\textit{central}$, where both leptons are reconstructed with $|\eta| < 1.4$ and $\textit{forward}$, where at least one leptons has to be reconstructed with $|\eta| > 1.6$.  

Leptons with small spatial separation can interfere with each other's reconstruction and isolation. These effects are different for electrons and muons, which can be seen in Figure~\ref{fig:cutJustification} (right). The ratio of electrons to muons first rises for lower values of $\Delta R(ll)$ before dropping for values below $0.1$. The leptons are therefore required to be separated in $\Delta R(ll)$ by more than 0.3. Some differences between electrons and muons can also be observed for very high values of $\Delta R(ll)$, but they are less pronounced and this region is less populated.  

\begin{figure}[htbp]
\centering
\begin{minipage}[t]{0.49\textwidth}
  \includegraphics[width=\textwidth]{plots/SELECTION/gapJustification.pdf}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
\includegraphics[width=\textwidth]{plots/SELECTION/dRJustification_eeVSmm.pdf}
\end{minipage}
\caption{istribution of $|\eta|$ (left) and $\Delta R(ll)$ (right) for the leading lepton for \MM (black dots) and \EE (red dots) events in a simulation of $t\bar{t}$ events. Both distributions are normalized to the same area.}
\label{fig:cutJustification}
\end{figure}    

As an additional requirement, to avoid possible reconstruction problems events with low lepton momenta and to avoid contamination from dilepton production in the decay of the bottonium resonances, the dilepton invariant mass \mll is required to be greater than $\unit{20}{\giga\electronvolt}$. 

\subsection{Selections in \MET and jet multiplicity}
Three subsets of the event sample obtained with the inclusive dilepton selection are defined, resulting in samples enriched in different processes. The variables used in the definitions of these regions are \MET and the number of selected jets $N_{jets}$. The selections are illustrated in the plots of Figure~\ref{fig:sigRegionBG}, which also show the distribution of $t\bar{t}$ (left) and Drell-Yan (right) events in the \MET-$N_{jets}$ plane. 
 
The signal region, in which the search will be performed, is defined by requiring either $N_{jets} \geq 3$ and $\MET > \unit{100}{\giga\electronvolt}$ or $N_{jets} \geq 3$ and $\MET > \unit{100}{\giga\electronvolt}$. This definition allows to select signal events for points in the parameter space where more energy is distributed to the jets and less to the invisible component of the signature and vice versa. At the same time the rejection of background events with both lower $N_{jets}$ and \MET is maintained. A control region dominated by flavour-symmetric processes is defined by selecting events with $N_{jets} = 2$ and $\unit{100}{\giga\electronvolt} < \MET < \unit{150}{\giga\electronvolt}$. 

To study lepton pairs produced via the Drell-Yan process and to obtain a high statistics sample of leptons for efficiency measurements, events with $N_{jets} \geq 2$ and $\MET < \unit{50}{\giga\electronvolt}$ are selected. The $N_{jet}$ requirement greatly reduces the statistics and the purity of this event sample. However, because of the large cross section of the Drell-Yan process, the event yield is still sufficient for the purposes of this analysis and Drell-Yan events dominate over those from $t\bar{t}$ production by two orders of magnitude. This allows to select events with kinematics close to those of the signal selection in terms of jet multiplicity.
\begin{figure}[htbp]
\centering
\begin{minipage}[t]{0.49\textwidth}
  \includegraphics[width=\textwidth]{plots/SELECTION/metJetsScatter_ttbar.pdf}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
\includegraphics[width=\textwidth]{plots/SELECTION/metJetsScatter_DY.pdf}
\end{minipage}
\caption{Distribution of backgrounds events in the \MET-$N_{jets}$ plane for $t\bar{t}$ (left) and Drell-Yan (right) events from Simulation. The events are weighted according to the cross section of the process and the size of the generated event sample, assuming an integrated luminosity of \lumi. The three regions defined in the plane are indicated by lines.}
\label{fig:sigRegionBG}
\end{figure}    
